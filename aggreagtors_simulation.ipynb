{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "aggreagtors_simulation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.11 64-bit ('federated': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "6ea880aaecdb5b53bae04aba85cace19329463687a7ea973cebb5393fa7909d2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install numpy\r\n",
        "!pip install matplotlib\r\n",
        "!pip install wquantiles\r\n",
        "!pip install scipy\r\n",
        "!pip install sklearn"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZEW6YidibPfP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from functools import partial\r\n",
        "from util.aggregators import mean, median, trimmed_mean, gamma_mean, geometric_median\r\n",
        "#from sklearn.decomposition import PCA, KernelPCA, SparsePCA, TruncatedSVD, IncrementalPCA\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def generate(p, m, gen_par):\r\n",
        "  \"\"\"\r\n",
        "  shape (m, p), p:#parameters, m:#machines\r\n",
        "  \"\"\"\r\n",
        "  if gen_par[\"distribution\"]==\"multi_norm\":\r\n",
        "    return gen_par[\"generator\"](gen_par[\"mu\"], gen_par[\"sigma\"], m)\r\n",
        "  elif gen_par[\"distribution\"]==\"t_dist\":\r\n",
        "    return gen_par[\"generator\"](gen_par[\"location\"], gen_par[\"shape\"], gen_par[\"df\"], m)\r\n",
        "\r\n",
        "#another usage\r\n",
        "#not sure which one is more convenient for our simulation\r\n",
        "#def generate(p, m, generator, *par):\r\n",
        "#  \"\"\"\r\n",
        "#  shape (m, p), p:#parameters, m:#machines\r\n",
        "#  \"\"\"\r\n",
        "#  if generator==\"multi_norm\":\r\n",
        "#    return np.random.multivariate_normal(*par, size = m)\r\n",
        "#data = generate(p=100, m=20, generator=\"multi_norm\", mu, sigma)\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "return data should be v1,v2,...\r\n",
        "v1,v2,... are np.array\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def bias(y_pred, y_true):\r\n",
        "    \"\"\"\r\n",
        "    y_pred: (max_ite, p)\r\n",
        "    y_true: (p,)\r\n",
        "    \"\"\"\r\n",
        "    return np.square(np.subtract(np.mean(y_pred, axis = 0),y_true)).mean()\r\n",
        "bias.__name__=\"bias\"\r\n",
        "\r\n",
        "def mse(y_pred, y_true):\r\n",
        "    \"\"\"\r\n",
        "    y_pred: (max_ite, p)\r\n",
        "    y_true: (p,)\r\n",
        "    \"\"\"\r\n",
        "    return np.mean([np.square(np.subtract(y_hat,y_true))  for y_hat in y_pred], axis = 0).mean()\r\n",
        "mse.__name__=\"mse\"\r\n",
        "\r\n",
        "def variance(y_pred, y_true):\r\n",
        "    \"\"\"\r\n",
        "    y_pred: (max_ite, p)\r\n",
        "    y_true: (p,)\r\n",
        "    \"\"\"\r\n",
        "    return np.mean([np.square( np.subtract( y_hat, np.mean(y_pred, axis = 0) ) )  for y_hat in y_pred], axis = 0).mean()\r\n",
        "variance.__name__=\"variance\"\r\n",
        "\r\n",
        "def compute_result(estimate, truth, metric):\r\n",
        "    \"\"\"\r\n",
        "    metric = [bias, mse, ...]\r\n",
        "    \"\"\"\r\n",
        "    result = []\r\n",
        "    for fn in metric:\r\n",
        "        result.append(fn(estimate,truth))\r\n",
        "    return np.array(result)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Yji9QqH3Sr9j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"\r\n",
        "p: dimension\r\n",
        "m: machines\r\n",
        "b: byz_machines\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def Gaussian_gen(mu, sigma):\r\n",
        "    return {\"distribution\": \"multi_norm\",\r\n",
        "          \"generator\": np.random.multivariate_normal,\r\n",
        "          \"mu\": mu,\r\n",
        "          \"sigma\": sigma \r\n",
        "          } \r\n",
        "        \r\n",
        "def t_gen(mu, sigma, df):\r\n",
        "    def multivariate_t_rvs(mu, S, df ,size):\r\n",
        "        '''generate random variables of multivariate t distribution\r\n",
        "        Parameters\r\n",
        "        ----------\r\n",
        "        mu : array_like\r\n",
        "            mean of random variable, length determines dimension of random variable\r\n",
        "        S : array_like\r\n",
        "            square array of covariance  matrix\r\n",
        "        df : int or float\r\n",
        "            degrees of freedom\r\n",
        "        size : int\r\n",
        "            number of observations, return random array will be (size, len(mu))\r\n",
        "        Returns\r\n",
        "        -------\r\n",
        "        rvs : ndarray, (size, len(mu))\r\n",
        "            each row is an independent draw of a multivariate t distributed\r\n",
        "            random variable\r\n",
        "        '''\r\n",
        "        mu = np.asarray(mu)\r\n",
        "        d = len(mu)\r\n",
        "        if df == np.inf:\r\n",
        "            x = 1.\r\n",
        "        else:\r\n",
        "            x = np.random.chisquare(df, size)/df\r\n",
        "        z = np.random.multivariate_normal(np.zeros(d),S,(size,))\r\n",
        "        return mu + z/np.sqrt(x)[:,None]\r\n",
        "    return {\"distribution\": \"t_dist\",\r\n",
        "          \"generator\": multivariate_t_rvs,\r\n",
        "          \"location\": mu,\r\n",
        "          \"shape\": sigma,\r\n",
        "          \"df\":df\r\n",
        "          }"
      ],
      "outputs": [],
      "metadata": {
        "id": "AUoWPaZkKRD6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"\r\n",
        "Scenario 1\r\n",
        "multiple experiments \r\n",
        "\r\n",
        "fix m=200 alpha=0 \r\n",
        "data from T distribution(df=3)\r\n",
        "when gamma=0.01\r\n",
        "get station and low bias/p when p goes to 1000\r\n",
        "bias/p about 0.01\r\n",
        "\r\n",
        "data from multi-normal distribution\r\n",
        "when gamma=0.01\r\n",
        "get station and low bias/p when p goes to 1000\r\n",
        "bias/p about 0.005\r\n",
        "\"\"\"\r\n",
        "#set seed\r\n",
        "seed = 2021\r\n",
        "\r\n",
        "\r\n",
        "m = 200 #Total machines\r\n",
        "alpha = 0\r\n",
        "b = int(m*alpha) #Byzantine machines\r\n",
        "simu_iter = 100 #number of experiments\r\n",
        "#gamma = 0.005\r\n",
        "beta = 0.1\r\n",
        "# p: dimension \r\n",
        "p_range = np.arange(20,1000,20)\r\n",
        "t_df = 5 # degree of freedom in t distribution\r\n",
        "\r\n",
        "metrics = [bias, mse, variance] #plot as below\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "for i, metric in enumerate(metrics):\r\n",
        "  plot results[dist][method][i_metrics,:] \r\n",
        "  ylab metric\r\n",
        "\"\"\" \r\n",
        "\r\n",
        "dist_list = [\"Gaussian\", \"T_dist\"]  #for convenience if one day we want to add more generate dist\r\n",
        "#declare a dictionary to map the generators to functions\r\n",
        "dist2fun = {\"Gaussian\":Gaussian_gen, \r\n",
        "            \"T_dist\":partial(t_gen, df = t_df)\r\n",
        "            }\r\n",
        "\r\n",
        "#for convenient if one day we want to add more aggregator\r\n",
        "method_list = [\"mean\",\"median\",\"gamma\",\"geo\",\"trim\"]\r\n",
        "\r\n",
        "#declare a dictionary, it is very convenient to add more object inside\r\n",
        "results=dict()\r\n",
        "\r\n",
        "#iterate all generators\r\n",
        "for dist in dist_list:\r\n",
        "  #to restore results\r\n",
        "  temp_result = dict()\r\n",
        "  for method in method_list:\r\n",
        "    temp_result[method] = np.zeros((len(metrics),len(p_range)))\r\n",
        "\r\n",
        "  for p in p_range:\r\n",
        "    mu = [0]*p\r\n",
        "    mu_byz = [100]*p\r\n",
        "    index = int((p / 20) - 1)\r\n",
        "    gamma = 2/p\r\n",
        "    #declare a dictionary to map the methods to functions\r\n",
        "    method2fun = {\"mean\":partial(mean, weights = None),\r\n",
        "                  \"median\":partial(median, weights = None),\r\n",
        "                  \"gamma\":partial(gamma_mean, weights = None, compute = 'simple', gamma = gamma),\r\n",
        "                  \"geo\":partial(geometric_median, weights = None),\r\n",
        "                  \"trim\":partial(trimmed_mean, weights = None, beta = beta)\r\n",
        "                  }\r\n",
        "    \r\n",
        "    gen_par = dist2fun[dist](mu, sigma=np.eye(p))\r\n",
        "    byz_par = dist2fun[dist](mu_byz, sigma=np.eye(p))\r\n",
        "\r\n",
        "    #to restore the estimation\r\n",
        "    temp = dict()\r\n",
        "    for method in method_list:\r\n",
        "      temp[method]=[]\r\n",
        "    #iterate many times\r\n",
        "    for t in range(simu_iter):\r\n",
        "      if int(p/20)==p/20:\r\n",
        "        print(\"Iterate: {} for dimension: {} with data generate from {}\".format(t,p,dist))\r\n",
        "      np.random.seed(seed + 100*t + p)\r\n",
        "      input = np.concatenate((generate(p, m-b, gen_par), generate(p, b, byz_par)), axis = 0) if b>0 else generate(p, m, gen_par)\r\n",
        "      for method in method_list:\r\n",
        "        temp[ method ].append( method2fun[ method ]( input ) )\r\n",
        "      #end repeating simulation for-loop\r\n",
        "    for method in method_list:\r\n",
        "      temp_result[method][:,index] = compute_result(temp[ method ], mu, metrics)\r\n",
        "    #end p_range for-loop\r\n",
        "  results [dist] = temp_result\r\n",
        "  #end dist_list for-loop"
      ],
      "outputs": [],
      "metadata": {
        "id": "NoqZBqXtDGGH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#plot the comparison of aggregators\r\n",
        "fig, axs = plt.subplots(3, 2, figsize=(20, 10), sharex=True, sharey='row',  gridspec_kw={'hspace': 0.2, 'wspace': 0.04})\r\n",
        "(ax1, ax2),  (ax3, ax4), (ax5, ax6)= axs\r\n",
        "\r\n",
        "ax1.set_title(\"Gaussian\")\r\n",
        "ax2.set_title('t-distribution(df=5)')\r\n",
        "right = [ax2, ax4, ax6]\r\n",
        "\r\n",
        "for i, metric in enumerate(metrics):\r\n",
        "  for j, dist in enumerate(dist_list):\r\n",
        "    ax = axs[i][j]\r\n",
        "    for method in method_list:\r\n",
        "      r = results[dist][method][i,:]\r\n",
        "      ax.plot(p_range, r, label = method) \r\n",
        "      ax.set_xlabel('p')\r\n",
        "      ax.set_xticks(p_range[np.arange(4,len(p_range),5)])\r\n",
        "    ax.set_ylabel(metric.__name__)\r\n",
        "for ax in right:\r\n",
        "  #method_list is [\"mean\",\"median\",\"gamma\",\"geo\",\"trim\"] need to use the same order\r\n",
        "  ax.legend(labels=['mean', 'median', '\\u03B3-mean with gamma=2/p', 'GeoMed', 'Trimmed-mean with beta = {}'.format(beta)],\r\n",
        "            loc='upper right',bbox_to_anchor=(1.4,1.0))\r\n",
        "plt.show()\r\n",
        "#fig.savefig('attackers_0%.pdf', format='pdf', bbox_inches='tight')"
      ],
      "outputs": [],
      "metadata": {
        "id": "AX39eCX5uDSc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"\r\n",
        "Scenario 2\r\n",
        "multiple experiments \r\n",
        "\r\n",
        "fix m=200 p=1000 \r\n",
        "data from multi-normal distribution\r\n",
        "when gamma=0.1\r\n",
        "get station and low bias/p when alpha goes to 0.5\r\n",
        "bias/p about 0.8 (senario 1: 0.01)\r\n",
        "\"\"\"\r\n",
        "seed = 2021\r\n",
        "\r\n",
        "\r\n",
        "m = 200 #Total machines\r\n",
        "simu_iter = 100 #number of experiments\r\n",
        "#gamma = 0.005\r\n",
        "beta = 0.1\r\n",
        "# p: dimension \r\n",
        "p = 1000\r\n",
        "alpha_range = np.arange(0.05,0.5,0.05)\r\n",
        "\r\n",
        "metrics = [bias, mse, variance] #plot as below\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "for i, metric in enumerate(metrics):\r\n",
        "  plot results[dist][method][i_metrics,:] \r\n",
        "  ylab metric\r\n",
        "\"\"\" \r\n",
        "\r\n",
        "dist_list = [\"Gaussian\", \"T_dist\"]  #for convenience if one day we want to add more generate dist\r\n",
        "#declare a dictionary to map the generators to functions\r\n",
        "dist2fun = {\"Gaussian\":Gaussian_gen, \r\n",
        "            \"T_dist\":partial(t_gen, df = 5)\r\n",
        "            }\r\n",
        "\r\n",
        "#for convenient if one day we want to add more aggregator\r\n",
        "method_list = [\"mean\",\"median\",\"gamma\",\"geo\",\"trim\"]\r\n",
        "\r\n",
        "#declare a dictionary, it is very convenient to add more object inside\r\n",
        "results=dict()\r\n",
        "\r\n",
        "#iterate all generators\r\n",
        "for dist in dist_list:\r\n",
        "  #to restore results\r\n",
        "  temp_result = dict()\r\n",
        "  for method in method_list:\r\n",
        "    temp_result[method] = np.zeros((len(metrics),len(alpha_range)))\r\n",
        "\r\n",
        "  for alpha in alpha_range:\r\n",
        "    b = int(m*alpha)\r\n",
        "    mu = [0]*p\r\n",
        "    mu_byz = [100]*p\r\n",
        "    index = int(20*alpha - 1)\r\n",
        "    gamma = 0.5/p\r\n",
        "    #declare a dictionary to map the methods to functions\r\n",
        "    method2fun = {\"mean\":partial(mean, weights = None),\r\n",
        "                  \"median\":partial(median, weights = None),\r\n",
        "                  \"gamma\":partial(gamma_mean, weights = None,compute = 'simple', gamma = gamma),\r\n",
        "                  \"geo\":partial(geometric_median, weights = None),\r\n",
        "                  \"trim\":partial(trimmed_mean, weights = None, beta = beta)\r\n",
        "                  }\r\n",
        "    \r\n",
        "    gen_par = dist2fun[dist](mu, sigma=np.eye(p))\r\n",
        "    byz_par = dist2fun[dist](mu_byz, sigma=np.eye(p))\r\n",
        "\r\n",
        "    #to restore the estimation\r\n",
        "    temp = dict()\r\n",
        "    for method in method_list:\r\n",
        "      temp[method]=[]\r\n",
        "    #iterate many times\r\n",
        "    for t in range(simu_iter):\r\n",
        "      np.random.seed(seed + 100*t + int(1000*alpha))\r\n",
        "      input = np.concatenate((generate(p, m-b, gen_par), generate(p, b, byz_par)), axis = 0) if b>0 else generate(p, m, gen_par)\r\n",
        "      for method in method_list:\r\n",
        "        temp[ method ].append( method2fun[ method ]( input ) )\r\n",
        "      #end repeating simulation for-loop\r\n",
        "    for method in method_list:\r\n",
        "      temp_result[method][:,index] = compute_result(temp[ method ], mu, metrics)\r\n",
        "    #end alpha_range for-loop\r\n",
        "  results [dist] = temp_result\r\n",
        "  #end dist_list for-loop     "
      ],
      "outputs": [],
      "metadata": {
        "id": "4mJOCu5K-VLL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#plot the comparison of aggregators\r\n",
        "fig, axs = plt.subplots(3, 2, figsize=(20, 10), sharex=True, sharey='row',  gridspec_kw={'hspace': 0.2, 'wspace': 0.04})\r\n",
        "(ax1, ax2),  (ax3, ax4), (ax5, ax6)= axs\r\n",
        "ax1.set_title(\"Gaussian\")\r\n",
        "ax2.set_title('t-distribution(df=5)')\r\n",
        "right = [ax2, ax4, ax6]\r\n",
        "\r\n",
        "for i, metric in enumerate(metrics):\r\n",
        "  for j, dist in enumerate(dist_list):\r\n",
        "    ax = axs[i][j]\r\n",
        "    for method in method_list:\r\n",
        "      r = results[dist][method][i,:]      \r\n",
        "      ax.plot(alpha_range, r, label = method) \r\n",
        "      ax.set_xlabel('\\u03B1') #alpha\r\n",
        "      #ax.set_xticks(alpha_range[np.arange(4,len(alpha_range),5)])\r\n",
        "    ax.set_ylabel(metric.__name__)\r\n",
        "for ax in right:\r\n",
        "  #method_list is [\"mean\",\"median\",\"gamma\",\"geo\",\"trim\"] need to use the same order\r\n",
        "  ax.legend(labels=['mean', 'median', '\\u03B3-mean with \\u03B3 = 2/p', 'GeoMed', 'Trimmed-mean with \\u03B2 = {}'.format(beta)],\r\n",
        "            loc='upper right',bbox_to_anchor=(1.4,1.0))\r\n",
        "  \r\n",
        "plt.suptitle('Testing different aggregatros across \\u03B1 ',fontsize=25)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "XAYr2nYc-aZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$(1+\\gamma)^{\\frac{p+2}{2}}e^{\\frac{-\\gamma}{2}(x_0-\\mu)^\\mathrm{T}\\mathbf{\\Sigma^{-1}}(x_0-\\mu)}(x_0-\\mu) $\n",
        "\n",
        "Althogh theory indicates that $\\gamma$-divergence reduces to KL-divergence as $\\gamma\\to 0$ , it seems like there is also a relation bewteen $p$ and $\\gamma$, assume to be $\\gamma=g(p)$, s.t. $\\|\\mu- \\hat\\mu\\|<c$  \n",
        " \n",
        " Maybe $p\\times\\gamma<0.1$.  "
      ],
      "metadata": {
        "id": "hJWf7E39WZX5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"    \r\n",
        "experiment on gamma with p\r\n",
        "scenario 3\r\n",
        "\"\"\"\r\n",
        "    \r\n",
        "seed = 2021\r\n",
        "\r\n",
        "\r\n",
        "m = 200 #Total machines\r\n",
        "alpha = 0.1 #Byzantine fraction\r\n",
        "simu_iter = 100 #number of experiments\r\n",
        "beta = 0.1\r\n",
        "# p: dimension \r\n",
        "p_range = np.arange(20,1000,20)\r\n",
        "\r\n",
        "\r\n",
        "metrics = [bias, mse, variance] #plot as below\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "for i, metric in enumerate(metrics):\r\n",
        "  plot results[dist][method][i_metrics,:] \r\n",
        "  ylab metric\r\n",
        "\"\"\" \r\n",
        "\r\n",
        "dist_list = [\"Gaussian\", \"T_dist\"]  #for convenience if one day we want to add more generate dist\r\n",
        "#declare a dictionary to map the generators to functions\r\n",
        "dist2fun = {\"Gaussian\":Gaussian_gen, \r\n",
        "            \"T_dist\":partial(t_gen, df = 5)\r\n",
        "            }\r\n",
        "\r\n",
        "#for convenient if one day we want to add more aggregator\r\n",
        "method_list = [\"gamma_0.5/p\",\"gamma_1/p\",\"gamma_2/p\",\"gamma_3/p\",\"gamma_4/p\"]\r\n",
        "\r\n",
        "#declare a dictionary, it is very convenient to add more object inside\r\n",
        "results={\"Gaussian\":None }\r\n",
        "\r\n",
        "#iterate all generators\r\n",
        "for dist in dist_list:\r\n",
        "  #to restore results\r\n",
        "  temp_result = dict()\r\n",
        "  for method in method_list:\r\n",
        "    temp_result[method] = np.zeros((len(metrics),len(p_range)))\r\n",
        "\r\n",
        "  for p in p_range:\r\n",
        "    b = int(m*alpha)\r\n",
        "    mu = [0]*p\r\n",
        "    mu_byz = [100]*p\r\n",
        "    index = int((p / 20) - 1)\r\n",
        "    gamma = [0.5/p, 1/p, 2/p, 3/p, 4/p]\r\n",
        "    #declare a dictionary to map the methods to functions\r\n",
        "    method2fun = {\"gamma_0.5/p\":partial(gamma_mean, weights = None, gamma = gamma[0]),\r\n",
        "                  \"gamma_1/p\":partial(gamma_mean, weights = None, compute = 'simple',  gamma = gamma[1]),\r\n",
        "                  \"gamma_2/p\":partial(gamma_mean, weights = None, compute = 'simple', gamma = gamma[2]),\r\n",
        "                  \"gamma_3/p\":partial(gamma_mean, weights = None, compute = 'simple', gamma = gamma[3]),\r\n",
        "                  \"gamma_4/p\":partial(gamma_mean, weights = None, compute = 'simple', gamma = gamma[4])\r\n",
        "                  }\r\n",
        "    \r\n",
        "    gen_par = dist2fun[dist](mu, sigma=np.eye(p))\r\n",
        "    byz_par = dist2fun[dist](mu_byz, sigma=np.eye(p))\r\n",
        "\r\n",
        "    #to restore the estimation\r\n",
        "    temp = dict()\r\n",
        "    for method in method_list:\r\n",
        "      temp[method]=[]\r\n",
        "    #iterate many times\r\n",
        "    for t in range(simu_iter):\r\n",
        "      np.random.seed(seed + 100*t + p)\r\n",
        "      input = np.concatenate((generate(p, m-b, gen_par), generate(p, b, byz_par)), axis = 0) if b>0 else generate(p, m, gen_par)\r\n",
        "      for method in method_list:\r\n",
        "        temp[ method ].append( method2fun[ method ]( input ) )\r\n",
        "      #end repeating simulation for-loop\r\n",
        "    for method in method_list:\r\n",
        "      temp_result[method][:,index] = compute_result(temp[ method ], mu, metrics)\r\n",
        "    #end alpha_range for-loop\r\n",
        "  results [dist] = temp_result\r\n",
        "  #end dist_list for-loop"
      ],
      "outputs": [],
      "metadata": {
        "id": "zSOTySMHWZw5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#plot comparison of different gammas\r\n",
        "fig, axs = plt.subplots(3, 2, figsize=(20, 10), sharex=True, sharey='row',  gridspec_kw={'hspace': 0.2, 'wspace': 0.04})\r\n",
        "\r\n",
        "(ax1, ax2),  (ax3, ax4), (ax5, ax6)= axs\r\n",
        "ax1.set_title(\"Gaussian\")\r\n",
        "ax2.set_title('t-distribution(df=5)')\r\n",
        "right = [ax2, ax4, ax6]\r\n",
        "\r\n",
        "for i, metric in enumerate(metrics):\r\n",
        "  for j, dist in enumerate(dist_list):\r\n",
        "    ax = axs[i][j]\r\n",
        "    for method in method_list:\r\n",
        "      r = results[dist][method][i,:]      \r\n",
        "      ax.plot(p_range, r, label = method)\r\n",
        "      ax.set_xlabel('p')\r\n",
        "      ax.set_xticks(p_range[np.arange(4,len(p_range),5)])\r\n",
        "    ax.set_ylabel(metric.__name__)\r\n",
        "\r\n",
        "for ax in right:\r\n",
        "  #method_list is [\"mean\",\"median\",\"gamma\",\"geo\",\"trim\"] need to use the same order\r\n",
        "  ax.legend(labels=['\\u03B3 = 0.5/p', '\\u03B3 = 1/p', '\\u03B3 = 2/p','\\u03B3 = 3/p', '\\u03B3 = 4/p']\r\n",
        "            ,loc='upper right',bbox_to_anchor=(1.2,1.0))\r\n",
        "plt.suptitle('Testing different \\u03B3 across dimension p, \\u03B1 = {}'.format(alpha),fontsize=25)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "aKcH19Bu9SND"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"\r\n",
        "fix m=200 alpha=0.1\r\n",
        "data from T distribution(df=3)\r\n",
        "\r\n",
        "test gamma_mean 2D and 1D\r\n",
        "\r\n",
        "Some bugs\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "#set seed\r\n",
        "seed = 2021\r\n",
        "\r\n",
        "\r\n",
        "m = 200 #Total machines\r\n",
        "alpha = 0.1\r\n",
        "b = int(m*alpha) #Byzantine machines\r\n",
        "simu_iter = 100 #number of experiments\r\n",
        "\r\n",
        "# p: dimension \r\n",
        "p_range = np.arange(20,1000,20)\r\n",
        "\r\n",
        "metrics = [bias, mse, variance] #plot as below\r\n",
        "\"\"\"\r\n",
        "for i, metric in enumerate(metrics):\r\n",
        "  plot results[dist][method][i_metrics,:] \r\n",
        "  ylab metric\r\n",
        "\"\"\" \r\n",
        "\r\n",
        "dist_list = [\"Gaussian\", \"T_dist\"]  #for convenience if one day we want to add more generate dist\r\n",
        "#declare a dictionary to map the generators to functions\r\n",
        "dist2fun = {\"Gaussian\":Gaussian_gen, \r\n",
        "            \"T_dist\":partial(t_gen, df = 5)\r\n",
        "            }\r\n",
        "\r\n",
        "#for convenient if one day we want to add more aggregator\r\n",
        "method_list = [\"gamma_1D\",\"gamma_2D\"]\r\n",
        "\r\n",
        "#declare a dictionary, it is very convenient to add more object inside\r\n",
        "results=dict()\r\n",
        "\r\n",
        "#iterate all generators\r\n",
        "for dist in dist_list:\r\n",
        "  #to restore results\r\n",
        "  temp_result = {\"gamma_1D\":None,\r\n",
        "                 \"gamma_2D\":None,}\r\n",
        "  for method in method_list:\r\n",
        "    temp_result[method] = np.zeros((len(metrics),len(p_range)))\r\n",
        "\r\n",
        "  for p in p_range:\r\n",
        "    mu = [0]*p\r\n",
        "    mu_byz = [100]*p\r\n",
        "    index = int((p / 20) - 1)\r\n",
        "    gamma = 2/p\r\n",
        "    #declare a dictionary to map the methods to functions\r\n",
        "    method2fun = {\"gamma_1D\":partial(gamma_mean, weights = None, compute = \"1D\", gamma = gamma),\r\n",
        "                  \"gamma_2D\":partial(gamma_mean, weights = None, compute = \"2D\", gamma = gamma, dim_red = True)\r\n",
        "                  }\r\n",
        "    gen_par = dist2fun[dist](mu, sigma=np.eye(p))\r\n",
        "    byz_par = dist2fun[dist](mu_byz, sigma=np.eye(p))\r\n",
        "\r\n",
        "    #to restore the estimation\r\n",
        "    temp = {\"gamma_1D\":None}\r\n",
        "    for method in method_list:\r\n",
        "      temp[method]=[]\r\n",
        "    #iterate many times\r\n",
        "    for t in range(simu_iter):\r\n",
        "      print(\"Iterate: {}\".format(t))\r\n",
        "      np.random.seed(seed + 100*t + p)\r\n",
        "      input = np.concatenate((generate(p, m-b, gen_par), generate(p, b, byz_par)), axis = 0) if b>0 else generate(p, m, gen_par)\r\n",
        "      for method in method_list:\r\n",
        "        temp[ method ].append( method2fun[ method ]( input ) )\r\n",
        "      #end repeating simulation for-loop\r\n",
        "    for method in method_list:\r\n",
        "      temp_result[method][:,index] = compute_result(temp[ method ], mu, metrics)\r\n",
        "    #end p_range for-loop\r\n",
        "  results [dist] = temp_result\r\n",
        "  #end dist_list for-loop"
      ],
      "outputs": [],
      "metadata": {
        "id": "837kFmpIueYY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#plot the comparison of aggregators\r\n",
        "fig, axs = plt.subplots(3, 2, figsize=(20, 10), sharex=True, sharey='row',  gridspec_kw={'hspace': 0.2, 'wspace': 0.04})\r\n",
        "(ax1, ax2),  (ax3, ax4), (ax5, ax6)= axs\r\n",
        "\r\n",
        "ax1.set_title(\"Gaussian\")\r\n",
        "ax2.set_title('T distribution(df=10)')\r\n",
        "right = [ax2, ax4, ax6]\r\n",
        "\r\n",
        "for i, metric in enumerate(metrics):\r\n",
        "  for j, dist in enumerate(dist_list):\r\n",
        "    ax = axs[i][j]\r\n",
        "    for method in method_list:\r\n",
        "      r = results[dist][method][i,:]\r\n",
        "      ax.plot(p_range, r, label = method) \r\n",
        "      ax.set_xlabel('p')\r\n",
        "      ax.set_xticks(p_range[np.arange(4,len(p_range),5)])\r\n",
        "    ax.set_ylabel(metric.__name__)\r\n",
        "for ax in right:\r\n",
        "  #method_list is [\"mean\",\"median\",\"gamma\",\"geo\",\"trim\"] need to use the same order\r\n",
        "  ax.legend(labels=['mean', 'median', 'gamma mean with gamma=2/p', 'geometric median', 'trim mean with beta = {}'.format(beta)],\r\n",
        "            loc='upper right',bbox_to_anchor=(1.4,1.0))\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "lMvnxBSLv6FR"
      }
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEW6YidibPfP"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install wquantiles\n",
        "!pip install scipy\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yji9QqH3Sr9j"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from util.aggregators import mean, median, trimmed_mean, gamma_mean, geometric_median\n",
        "#from sklearn.decomposition import PCA, KernelPCA, SparsePCA, TruncatedSVD, IncrementalPCA\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate(p, m, gen_par):\n",
        "  \"\"\"\n",
        "  shape (m, p), p:#parameters, m:#machines\n",
        "  \"\"\"\n",
        "  if gen_par[\"distribution\"]==\"multi_norm\":\n",
        "    return gen_par[\"generator\"](gen_par[\"mu\"], gen_par[\"sigma\"], m)\n",
        "  elif gen_par[\"distribution\"]==\"t_dist\":\n",
        "    return gen_par[\"generator\"](gen_par[\"location\"], gen_par[\"shape\"], gen_par[\"df\"], m)\n",
        "\n",
        "#another usage\n",
        "#not sure which one is more convenient for our simulation\n",
        "#def generate(p, m, generator, *par):\n",
        "#  \"\"\"\n",
        "#  shape (m, p), p:#parameters, m:#machines\n",
        "#  \"\"\"\n",
        "#  if generator==\"multi_norm\":\n",
        "#    return np.random.multivariate_normal(*par, size = m)\n",
        "#data = generate(p=100, m=20, generator=\"multi_norm\", mu, sigma)\n",
        "\n",
        "\"\"\"\n",
        "return data should be v1,v2,...\n",
        "v1,v2,... are np.array\n",
        "\"\"\"\n",
        "\n",
        "def bias(y_pred, y_true):\n",
        "    \"\"\"\n",
        "    y_pred: (max_ite, p)\n",
        "    y_true: (p,)\n",
        "    \"\"\"\n",
        "    return np.square(np.subtract(np.mean(y_pred, axis = 0),y_true)).mean()\n",
        "bias.__name__=\"bias\"\n",
        "\n",
        "def mse(y_pred, y_true):\n",
        "    \"\"\"\n",
        "    y_pred: (max_ite, p)\n",
        "    y_true: (p,)\n",
        "    \"\"\"\n",
        "    return np.mean([np.square(np.subtract(y_hat,y_true))  for y_hat in y_pred], axis = 0).mean()\n",
        "mse.__name__=\"mse\"\n",
        "\n",
        "def variance(y_pred, y_true):\n",
        "    \"\"\"\n",
        "    y_pred: (max_ite, p)\n",
        "    y_true: (p,)\n",
        "    \"\"\"\n",
        "    return np.mean([np.square( np.subtract( y_hat, np.mean(y_pred, axis = 0) ) )  for y_hat in y_pred], axis = 0).mean()\n",
        "variance.__name__=\"variance\"\n",
        "\n",
        "def compute_result(estimate, truth, metric):\n",
        "    \"\"\"\n",
        "    metric = [bias, mse, ...]\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for fn in metric:\n",
        "        result.append(fn(estimate,truth))\n",
        "    return np.array(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUoWPaZkKRD6"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "p: dimension\n",
        "m: machines\n",
        "b: byz_machines\n",
        "\"\"\"\n",
        "\n",
        "def Gaussian_gen(mu, sigma):\n",
        "    return {\"distribution\": \"multi_norm\",\n",
        "          \"generator\": np.random.multivariate_normal,\n",
        "          \"mu\": mu,\n",
        "          \"sigma\": sigma \n",
        "          } \n",
        "        \n",
        "def t_gen(mu, sigma, df):\n",
        "    def multivariate_t_rvs(mu, S, df ,size):\n",
        "        '''generate random variables of multivariate t distribution\n",
        "        Parameters\n",
        "        ----------\n",
        "        mu : array_like\n",
        "            mean of random variable, length determines dimension of random variable\n",
        "        S : array_like\n",
        "            square array of covariance  matrix\n",
        "        df : int or float\n",
        "            degrees of freedom\n",
        "        size : int\n",
        "            number of observations, return random array will be (size, len(mu))\n",
        "        Returns\n",
        "        -------\n",
        "        rvs : ndarray, (size, len(mu))\n",
        "            each row is an independent draw of a multivariate t distributed\n",
        "            random variable\n",
        "        '''\n",
        "        mu = np.asarray(mu)\n",
        "        d = len(mu)\n",
        "        if df == np.inf:\n",
        "            x = 1.\n",
        "        else:\n",
        "            x = np.random.chisquare(df, size)/df\n",
        "        z = np.random.multivariate_normal(np.zeros(d),S,(size,))\n",
        "        return mu + z/np.sqrt(x)[:,None]\n",
        "    return {\"distribution\": \"t_dist\",\n",
        "          \"generator\": multivariate_t_rvs,\n",
        "          \"location\": mu,\n",
        "          \"shape\": sigma,\n",
        "          \"df\":df\n",
        "          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoqZBqXtDGGH"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Scenario 1\n",
        "multiple experiments \n",
        "\n",
        "fix m=200 alpha=0 \n",
        "data from T distribution(df=3)\n",
        "when gamma=0.01\n",
        "get station and low bias/p when p goes to 1000\n",
        "bias/p about 0.01\n",
        "\n",
        "data from multi-normal distribution\n",
        "when gamma=0.01\n",
        "get station and low bias/p when p goes to 1000\n",
        "bias/p about 0.005\n",
        "\"\"\"\n",
        "#set seed\n",
        "seed = 2021\n",
        "\n",
        "\n",
        "m = 200 #Total machines\n",
        "alpha = 0\n",
        "b = int(m*alpha) #Byzantine machines\n",
        "simu_iter = 100 #number of experiments\n",
        "#gamma = 0.005\n",
        "beta = 0.1\n",
        "# p: dimension \n",
        "p_range = np.arange(20,1000,20)\n",
        "t_df = 5 # degree of freedom in t distribution\n",
        "\n",
        "metrics = [bias, mse, variance] #plot as below\n",
        "\n",
        "\"\"\"\n",
        "for i, metric in enumerate(metrics):\n",
        "  plot results[dist][method][i_metrics,:] \n",
        "  ylab metric\n",
        "\"\"\" \n",
        "\n",
        "dist_list = [\"Gaussian\", \"T_dist\"]  #for convenience if one day we want to add more generate dist\n",
        "#declare a dictionary to map the generators to functions\n",
        "dist2fun = {\"Gaussian\":Gaussian_gen, \n",
        "            \"T_dist\":partial(t_gen, df = t_df)\n",
        "            }\n",
        "\n",
        "#for convenient if one day we want to add more aggregator\n",
        "method_list = [\"mean\",\"median\",\"gamma\",\"geo\",\"trim\"]\n",
        "\n",
        "#declare a dictionary, it is very convenient to add more object inside\n",
        "results=dict()\n",
        "\n",
        "#iterate all generators\n",
        "for dist in dist_list:\n",
        "  #to restore results\n",
        "  temp_result = dict()\n",
        "  for method in method_list:\n",
        "    temp_result[method] = np.zeros((len(metrics),len(p_range)))\n",
        "\n",
        "  for p in p_range:\n",
        "    mu = [0]*p\n",
        "    mu_byz = [100]*p\n",
        "    index = int((p / 20) - 1)\n",
        "    gamma = 2/p\n",
        "    #declare a dictionary to map the methods to functions\n",
        "    method2fun = {\"mean\":partial(mean, weights = None),\n",
        "                  \"median\":partial(median, weights = None),\n",
        "                  \"gamma\":partial(gamma_mean, weights = None, compute = 'simple', gamma = gamma),\n",
        "                  \"geo\":partial(geometric_median, weights = None),\n",
        "                  \"trim\":partial(trimmed_mean, weights = None, beta = beta)\n",
        "                  }\n",
        "    \n",
        "    gen_par = dist2fun[dist](mu, sigma=np.eye(p))\n",
        "    byz_par = dist2fun[dist](mu_byz, sigma=np.eye(p))\n",
        "\n",
        "    #to restore the estimation\n",
        "    temp = dict()\n",
        "    for method in method_list:\n",
        "      temp[method]=[]\n",
        "    #iterate many times\n",
        "    for t in range(simu_iter):\n",
        "      if int(p/20)==p/20:\n",
        "        print(\"Iterate: {} for dimension: {} with data generate from {}\".format(t,p,dist))\n",
        "      np.random.seed(seed + 100*t + p)\n",
        "      input = np.concatenate((generate(p, m-b, gen_par), generate(p, b, byz_par)), axis = 0) if b>0 else generate(p, m, gen_par)\n",
        "      for method in method_list:\n",
        "        temp[ method ].append( method2fun[ method ]( input ) )\n",
        "      #end repeating simulation for-loop\n",
        "    for method in method_list:\n",
        "      temp_result[method][:,index] = compute_result(temp[ method ], mu, metrics)\n",
        "    #end p_range for-loop\n",
        "  results [dist] = temp_result\n",
        "  #end dist_list for-loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AX39eCX5uDSc"
      },
      "outputs": [],
      "source": [
        "#plot the comparison of aggregators\n",
        "fig, axs = plt.subplots(3, 2, figsize=(20, 10), sharex=True, sharey='row',  gridspec_kw={'hspace': 0.2, 'wspace': 0.04})\n",
        "(ax1, ax2),  (ax3, ax4), (ax5, ax6)= axs\n",
        "\n",
        "ax1.set_title(\"Gaussian\")\n",
        "ax2.set_title('t-distribution(df=5)')\n",
        "right = [ax2, ax4, ax6]\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "  for j, dist in enumerate(dist_list):\n",
        "    ax = axs[i][j]\n",
        "    for method in method_list:\n",
        "      r = results[dist][method][i,:]\n",
        "      ax.plot(p_range, r, label = method) \n",
        "      ax.set_xlabel('p')\n",
        "      ax.set_xticks(p_range[np.arange(4,len(p_range),5)])\n",
        "    ax.set_ylabel(metric.__name__)\n",
        "for ax in right:\n",
        "  #method_list is [\"mean\",\"median\",\"gamma\",\"geo\",\"trim\"] need to use the same order\n",
        "  ax.legend(labels=['mean', 'median', '\\u03B3-mean with gamma=2/p', 'GeoMed', 'Trimmed-mean with beta = {}'.format(beta)],\n",
        "            loc='upper right',bbox_to_anchor=(1.4,1.0))\n",
        "plt.show()\n",
        "#fig.savefig('attackers_0%.pdf', format='pdf', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mJOCu5K-VLL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Scenario 2\n",
        "multiple experiments \n",
        "\n",
        "fix m=200 p=1000 \n",
        "data from multi-normal distribution\n",
        "when gamma=0.1\n",
        "get station and low bias/p when alpha goes to 0.5\n",
        "bias/p about 0.8 (senario 1: 0.01)\n",
        "\"\"\"\n",
        "seed = 2021\n",
        "\n",
        "\n",
        "m = 200 #Total machines\n",
        "simu_iter = 100 #number of experiments\n",
        "#gamma = 0.005\n",
        "beta = 0.1\n",
        "# p: dimension \n",
        "p = 1000\n",
        "alpha_range = np.arange(0.05,0.5,0.05)\n",
        "\n",
        "metrics = [bias, mse, variance] #plot as below\n",
        "\n",
        "\"\"\"\n",
        "for i, metric in enumerate(metrics):\n",
        "  plot results[dist][method][i_metrics,:] \n",
        "  ylab metric\n",
        "\"\"\" \n",
        "\n",
        "dist_list = [\"Gaussian\", \"T_dist\"]  #for convenience if one day we want to add more generate dist\n",
        "#declare a dictionary to map the generators to functions\n",
        "dist2fun = {\"Gaussian\":Gaussian_gen, \n",
        "            \"T_dist\":partial(t_gen, df = 5)\n",
        "            }\n",
        "\n",
        "#for convenient if one day we want to add more aggregator\n",
        "method_list = [\"mean\",\"median\",\"gamma\",\"geo\",\"trim\"]\n",
        "\n",
        "#declare a dictionary, it is very convenient to add more object inside\n",
        "results=dict()\n",
        "\n",
        "#iterate all generators\n",
        "for dist in dist_list:\n",
        "  #to restore results\n",
        "  temp_result = dict()\n",
        "  for method in method_list:\n",
        "    temp_result[method] = np.zeros((len(metrics),len(alpha_range)))\n",
        "\n",
        "  for alpha in alpha_range:\n",
        "    b = int(m*alpha)\n",
        "    mu = [0]*p\n",
        "    mu_byz = [100]*p\n",
        "    index = int(20*alpha - 1)\n",
        "    gamma = 0.5/p\n",
        "    #declare a dictionary to map the methods to functions\n",
        "    method2fun = {\"mean\":partial(mean, weights = None),\n",
        "                  \"median\":partial(median, weights = None),\n",
        "                  \"gamma\":partial(gamma_mean, weights = None,compute = 'simple', gamma = gamma),\n",
        "                  \"geo\":partial(geometric_median, weights = None),\n",
        "                  \"trim\":partial(trimmed_mean, weights = None, beta = beta)\n",
        "                  }\n",
        "    \n",
        "    gen_par = dist2fun[dist](mu, sigma=np.eye(p))\n",
        "    byz_par = dist2fun[dist](mu_byz, sigma=np.eye(p))\n",
        "\n",
        "    #to restore the estimation\n",
        "    temp = dict()\n",
        "    for method in method_list:\n",
        "      temp[method]=[]\n",
        "    #iterate many times\n",
        "    for t in range(simu_iter):\n",
        "      np.random.seed(seed + 100*t + int(1000*alpha))\n",
        "      input = np.concatenate((generate(p, m-b, gen_par), generate(p, b, byz_par)), axis = 0) if b>0 else generate(p, m, gen_par)\n",
        "      for method in method_list:\n",
        "        temp[ method ].append( method2fun[ method ]( input ) )\n",
        "      #end repeating simulation for-loop\n",
        "    for method in method_list:\n",
        "      temp_result[method][:,index] = compute_result(temp[ method ], mu, metrics)\n",
        "    #end alpha_range for-loop\n",
        "  results [dist] = temp_result\n",
        "  #end dist_list for-loop     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAYr2nYc-aZN"
      },
      "outputs": [],
      "source": [
        "#plot the comparison of aggregators\n",
        "fig, axs = plt.subplots(3, 2, figsize=(20, 10), sharex=True, sharey='row',  gridspec_kw={'hspace': 0.2, 'wspace': 0.04})\n",
        "(ax1, ax2),  (ax3, ax4), (ax5, ax6)= axs\n",
        "ax1.set_title(\"Gaussian\")\n",
        "ax2.set_title('t-distribution(df=5)')\n",
        "right = [ax2, ax4, ax6]\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "  for j, dist in enumerate(dist_list):\n",
        "    ax = axs[i][j]\n",
        "    for method in method_list:\n",
        "      r = results[dist][method][i,:]      \n",
        "      ax.plot(alpha_range, r, label = method) \n",
        "      ax.set_xlabel('\\u03B1') #alpha\n",
        "      #ax.set_xticks(alpha_range[np.arange(4,len(alpha_range),5)])\n",
        "    ax.set_ylabel(metric.__name__)\n",
        "for ax in right:\n",
        "  #method_list is [\"mean\",\"median\",\"gamma\",\"geo\",\"trim\"] need to use the same order\n",
        "  ax.legend(labels=['mean', 'median', '\\u03B3-mean with \\u03B3 = 2/p', 'GeoMed', 'Trimmed-mean with \\u03B2 = {}'.format(beta)],\n",
        "            loc='upper right',bbox_to_anchor=(1.4,1.0))\n",
        "  \n",
        "plt.suptitle('Testing different aggregatros across \\u03B1 ',fontsize=25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJWf7E39WZX5"
      },
      "source": [
        "$(1+\\gamma)^{\\frac{p+2}{2}}e^{\\frac{-\\gamma}{2}(x_0-\\mu)^\\mathrm{T}\\mathbf{\\Sigma^{-1}}(x_0-\\mu)}(x_0-\\mu) $\n",
        "\n",
        "Althogh theory indicates that $\\gamma$-divergence reduces to KL-divergence as $\\gamma\\to 0$ , it seems like there is also a relation bewteen $p$ and $\\gamma$, assume to be $\\gamma=g(p)$, s.t. $\\|\\mu- \\hat\\mu\\|<c$  \n",
        " \n",
        " Maybe $p\\times\\gamma<0.1$.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSOTySMHWZw5"
      },
      "outputs": [],
      "source": [
        "\"\"\"    \n",
        "experiment on gamma with p\n",
        "scenario 3\n",
        "\"\"\"\n",
        "    \n",
        "seed = 2021\n",
        "\n",
        "\n",
        "m = 200 #Total machines\n",
        "alpha = 0.1 #Byzantine fraction\n",
        "simu_iter = 100 #number of experiments\n",
        "beta = 0.1\n",
        "# p: dimension \n",
        "p_range = np.arange(20,1000,20)\n",
        "\n",
        "\n",
        "metrics = [bias, mse, variance] #plot as below\n",
        "\n",
        "\"\"\"\n",
        "for i, metric in enumerate(metrics):\n",
        "  plot results[dist][method][i_metrics,:] \n",
        "  ylab metric\n",
        "\"\"\" \n",
        "\n",
        "dist_list = [\"Gaussian\", \"T_dist\"]  #for convenience if one day we want to add more generate dist\n",
        "#declare a dictionary to map the generators to functions\n",
        "dist2fun = {\"Gaussian\":Gaussian_gen, \n",
        "            \"T_dist\":partial(t_gen, df = 5)\n",
        "            }\n",
        "\n",
        "#for convenient if one day we want to add more aggregator\n",
        "method_list = [\"gamma_0.5/p\",\"gamma_1/p\",\"gamma_2/p\",\"gamma_3/p\",\"gamma_4/p\"]\n",
        "\n",
        "#declare a dictionary, it is very convenient to add more object inside\n",
        "results={\"Gaussian\":None }\n",
        "\n",
        "#iterate all generators\n",
        "for dist in dist_list:\n",
        "  #to restore results\n",
        "  temp_result = dict()\n",
        "  for method in method_list:\n",
        "    temp_result[method] = np.zeros((len(metrics),len(p_range)))\n",
        "\n",
        "  for p in p_range:\n",
        "    b = int(m*alpha)\n",
        "    mu = [0]*p\n",
        "    mu_byz = [100]*p\n",
        "    index = int((p / 20) - 1)\n",
        "    gamma = [0.5/p, 1/p, 2/p, 3/p, 4/p]\n",
        "    #declare a dictionary to map the methods to functions\n",
        "    method2fun = {\"gamma_0.5/p\":partial(gamma_mean, weights = None, gamma = gamma[0]),\n",
        "                  \"gamma_1/p\":partial(gamma_mean, weights = None, compute = 'simple',  gamma = gamma[1]),\n",
        "                  \"gamma_2/p\":partial(gamma_mean, weights = None, compute = 'simple', gamma = gamma[2]),\n",
        "                  \"gamma_3/p\":partial(gamma_mean, weights = None, compute = 'simple', gamma = gamma[3]),\n",
        "                  \"gamma_4/p\":partial(gamma_mean, weights = None, compute = 'simple', gamma = gamma[4])\n",
        "                  }\n",
        "    \n",
        "    gen_par = dist2fun[dist](mu, sigma=np.eye(p))\n",
        "    byz_par = dist2fun[dist](mu_byz, sigma=np.eye(p))\n",
        "\n",
        "    #to restore the estimation\n",
        "    temp = dict()\n",
        "    for method in method_list:\n",
        "      temp[method]=[]\n",
        "    #iterate many times\n",
        "    for t in range(simu_iter):\n",
        "      np.random.seed(seed + 100*t + p)\n",
        "      input = np.concatenate((generate(p, m-b, gen_par), generate(p, b, byz_par)), axis = 0) if b>0 else generate(p, m, gen_par)\n",
        "      for method in method_list:\n",
        "        temp[ method ].append( method2fun[ method ]( input ) )\n",
        "      #end repeating simulation for-loop\n",
        "    for method in method_list:\n",
        "      temp_result[method][:,index] = compute_result(temp[ method ], mu, metrics)\n",
        "    #end alpha_range for-loop\n",
        "  results [dist] = temp_result\n",
        "  #end dist_list for-loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKcH19Bu9SND"
      },
      "outputs": [],
      "source": [
        "#plot comparison of different gammas\n",
        "fig, axs = plt.subplots(3, 2, figsize=(20, 10), sharex=True, sharey='row',  gridspec_kw={'hspace': 0.2, 'wspace': 0.04})\n",
        "\n",
        "(ax1, ax2),  (ax3, ax4), (ax5, ax6)= axs\n",
        "ax1.set_title(\"Gaussian\")\n",
        "ax2.set_title('t-distribution(df=5)')\n",
        "right = [ax2, ax4, ax6]\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "  for j, dist in enumerate(dist_list):\n",
        "    ax = axs[i][j]\n",
        "    for method in method_list:\n",
        "      r = results[dist][method][i,:]      \n",
        "      ax.plot(p_range, r, label = method)\n",
        "      ax.set_xlabel('p')\n",
        "      ax.set_xticks(p_range[np.arange(4,len(p_range),5)])\n",
        "    ax.set_ylabel(metric.__name__)\n",
        "\n",
        "for ax in right:\n",
        "  #method_list is [\"mean\",\"median\",\"gamma\",\"geo\",\"trim\"] need to use the same order\n",
        "  ax.legend(labels=['\\u03B3 = 0.5/p', '\\u03B3 = 1/p', '\\u03B3 = 2/p','\\u03B3 = 3/p', '\\u03B3 = 4/p']\n",
        "            ,loc='upper right',bbox_to_anchor=(1.2,1.0))\n",
        "plt.suptitle('Testing different \\u03B3 across dimension p, \\u03B1 = {}'.format(alpha),fontsize=25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "837kFmpIueYY"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "fix m=200 alpha=0.1\n",
        "data from T distribution(df=3)\n",
        "\n",
        "test gamma_mean 2D and 1D\n",
        "\n",
        "Some bugs\n",
        "\n",
        "\"\"\"\n",
        "#set seed\n",
        "seed = 2021\n",
        "\n",
        "\n",
        "m = 200 #Total machines\n",
        "alpha = 0.1\n",
        "b = int(m*alpha) #Byzantine machines\n",
        "simu_iter = 100 #number of experiments\n",
        "\n",
        "# p: dimension \n",
        "p_range = np.arange(20,1000,20)\n",
        "\n",
        "metrics = [bias, mse, variance] #plot as below\n",
        "\"\"\"\n",
        "for i, metric in enumerate(metrics):\n",
        "  plot results[dist][method][i_metrics,:] \n",
        "  ylab metric\n",
        "\"\"\" \n",
        "\n",
        "dist_list = [\"Gaussian\", \"T_dist\"]  #for convenience if one day we want to add more generate dist\n",
        "#declare a dictionary to map the generators to functions\n",
        "dist2fun = {\"Gaussian\":Gaussian_gen, \n",
        "            \"T_dist\":partial(t_gen, df = 5)\n",
        "            }\n",
        "\n",
        "#for convenient if one day we want to add more aggregator\n",
        "method_list = [\"gamma_1D\",\"gamma_2D\"]\n",
        "\n",
        "#declare a dictionary, it is very convenient to add more object inside\n",
        "results=dict()\n",
        "\n",
        "#iterate all generators\n",
        "for dist in dist_list:\n",
        "  #to restore results\n",
        "  temp_result = {\"gamma_1D\":None,\n",
        "                 \"gamma_2D\":None,}\n",
        "  for method in method_list:\n",
        "    temp_result[method] = np.zeros((len(metrics),len(p_range)))\n",
        "\n",
        "  for p in p_range:\n",
        "    mu = [0]*p\n",
        "    mu_byz = [100]*p\n",
        "    index = int((p / 20) - 1)\n",
        "    gamma = 2/p\n",
        "    #declare a dictionary to map the methods to functions\n",
        "    method2fun = {\"gamma_1D\":partial(gamma_mean, weights = None, compute = \"1D\", gamma = gamma),\n",
        "                  \"gamma_2D\":partial(gamma_mean, weights = None, compute = \"2D\", gamma = gamma, dim_red = True)\n",
        "                  }\n",
        "    gen_par = dist2fun[dist](mu, sigma=np.eye(p))\n",
        "    byz_par = dist2fun[dist](mu_byz, sigma=np.eye(p))\n",
        "\n",
        "    #to restore the estimation\n",
        "    temp = {\"gamma_1D\":None}\n",
        "    for method in method_list:\n",
        "      temp[method]=[]\n",
        "    #iterate many times\n",
        "    for t in range(simu_iter):\n",
        "      print(\"Iterate: {}\".format(t))\n",
        "      np.random.seed(seed + 100*t + p)\n",
        "      input = np.concatenate((generate(p, m-b, gen_par), generate(p, b, byz_par)), axis = 0) if b>0 else generate(p, m, gen_par)\n",
        "      for method in method_list:\n",
        "        temp[ method ].append( method2fun[ method ]( input ) )\n",
        "      #end repeating simulation for-loop\n",
        "    for method in method_list:\n",
        "      temp_result[method][:,index] = compute_result(temp[ method ], mu, metrics)\n",
        "    #end p_range for-loop\n",
        "  results [dist] = temp_result\n",
        "  #end dist_list for-loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMvnxBSLv6FR"
      },
      "outputs": [],
      "source": [
        "#plot the comparison of aggregators\n",
        "fig, axs = plt.subplots(3, 2, figsize=(20, 10), sharex=True, sharey='row',  gridspec_kw={'hspace': 0.2, 'wspace': 0.04})\n",
        "(ax1, ax2),  (ax3, ax4), (ax5, ax6)= axs\n",
        "\n",
        "ax1.set_title(\"Gaussian\")\n",
        "ax2.set_title('T distribution(df=10)')\n",
        "right = [ax2, ax4, ax6]\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "  for j, dist in enumerate(dist_list):\n",
        "    ax = axs[i][j]\n",
        "    for method in method_list:\n",
        "      r = results[dist][method][i,:]\n",
        "      ax.plot(p_range, r, label = method) \n",
        "      ax.set_xlabel('p')\n",
        "      ax.set_xticks(p_range[np.arange(4,len(p_range),5)])\n",
        "    ax.set_ylabel(metric.__name__)\n",
        "for ax in right:\n",
        "  #method_list is [\"mean\",\"median\",\"gamma\",\"geo\",\"trim\"] need to use the same order\n",
        "  ax.legend(labels=['mean', 'median', 'gamma mean with gamma=2/p', 'geometric median', 'trim mean with beta = {}'.format(beta)],\n",
        "            loc='upper right',bbox_to_anchor=(1.4,1.0))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "aggreagtors_simulation.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "interpreter": {
      "hash": "6ea880aaecdb5b53bae04aba85cace19329463687a7ea973cebb5393fa7909d2"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 64-bit ('federated': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
